# 数据科学大作业-源码分析

## 1. dataSets

存放爬取数据

### 1.1 bilibili

1. **json文件**

   1. 原始爬取数据，部分b站up主，文件格式 .json
   2. 示例：![image-20210119222637859](img\image-20210119222637859.png)

2. **样本**：处理后的数据

   1. 机器学习的训练集、提取出的弹幕的csv文件和预测情感后的csv文件等

      ![image-20210119222820365](img\image-20210119222820365.png)

### 1.2 sina

存放新浪数据集

1. **样本**：机器学习的训练集、提取出的弹幕的csv文件和预测情感后的csv文件等

   ![image-20210119223019946](img\image-20210119223019946.png)

2. **原始爬取数据：**![image-20210119223044549](img\image-20210119223044549.png)

3. **word2vec模型语料库**：![image-20210119223143176](img\image-20210119223143176.png)

4. **使用机器学习模型预测情感后的数据**：![image-20210119223308316](img\image-20210119223308316.png)

## 2. model

### 2.1 情感分析机器学习模型

![image-20210119223409484](img\image-20210119223409484.png)

### 2.2 word2vec模型

![image-20210119223432546](img\image-20210119223432546.png)

## 3. scripts

> 代码

### 3.1 crawler (爬虫代码)

![image-20210119223728526](img\image-20210119223728526.png)

1. **bilibili_crawler**
   1. 作用：爬取b站数据
   2. 解析：源码中有注释
2. **sina_crawler**
   1. 作用：爬取新浪新闻正文、评论等信息
   2. 解析：源码中有注释

### 3.2 data_process(数据分析代码)

1. **data_filter**
   1. 作用：数据过滤，筛选出符合要求的数据
   2. 解析：源码中有注释
2. **nlp_test**
   1. 作用：使用Hanlp, snownlp等已有模型进行情感预测，测试准确率
   2. 结论：准确率在**50% - 60%**左右
3. **nlp**
   1. 作用：训练情感分析机器学习模型与word2vec模型
   2. 解析：源码中有注释
   3. 最终训练模型：训练集准确率在**99%**以上，测试集准确率在 **85%**左右

## 4. stopwords (停用词表)

来源：https://github.com/goto456/stopwords

## 5. normal (高斯分布)

data.json：原始新闻数据

num.json：点击数数据

result.json：热点新闻数据

article.py：生成热点新闻数据

curvefit.py：拟合曲线

## 6. charts(可视化)

### 数据可视化

### 1.词云

基于WordCloud库实现。从已经获得并经过前期处理的新闻集中读取所有新闻并将其按新闻日期重新排列。再按每一天查找已经分析得到的新闻关键词。输入WordCloud提供的API,得到词云

#### 读取新闻并重排列

```python
import json
def load_files(path):
    with open(path, 'r') as f:
        return json.load(f)
    

def arrange(news):
    #news是传入的load完的json文件
    daily = dict()
    monthly = dict()
    news_list = {"daily": daily, "monthly": monthly} #提供按天和按月两种查看方式
    for year in range(2019, 2021):
        for month in range(1, 13):
            mon = tostr(year) + "-" + tostr(month)
            monLst = []
            for day in range(1, 32):
                date = tostr(year) + "-" + tostr(month) + "-" + tostr(day)
                lst = []
                for new in news:
                    if new["create_date"] == date: #如果和新闻的日期相同,就把新闻加入列表
                        lst.append(new)
                        monLst.append(new)
                if len(lst) != 0:
                    #如果列表为空,就不加入字典了
                    daily[date] = lst
            if len(monLst) != 0:
                monthly[mon] = monLst
    #返回一个字典,key值为"daily"、"monthly",分别对应按日、按月重排列结果的日期为key值的字典.
    return news_list
```

#### 调用WordCloud库

```python
def draw(keywords, date, mas):
    text = " ".join(keywords) #把关键词排成一段话
    try:
        text = text.replace("新浪", "")
        text = text.replace("新闻", "")
        #简易的过滤,去掉新浪新闻
    except:
        pass
    cloud = WordCloud(
        background_color='white',
        # 设置背景宽
        width=1920,
        font_path="HGKT_CNKI.TTF",
        # 设置背景高
        height=1080,
        mode='RGBA',
        mask=mas
    )
    word_cloud = cloud.generate(text)
    word_cloud.to_file("picture/" + date + ".png")
```

#### 样图

![2020-1-30词云](https://www.rubisco.cn/picturebed/2020-01-30.png)

### 2.新浪新闻及评论、B站弹幕统计图表

基于Pyecharts库实现。通过对数据集先分主题、再分时间，实现精细化划分评论。此时可以统计评论、新闻数量。再根据已经预测好的情感，和可以获取的点赞数实现加权、不加权的情感平均

#### 按主题和按时间分类

```python
def arrangeByTime(news):
    #类似上文arrange，不做赘述
    daily = dict()
    monthly = dict()
    days = dict()
    news_list = {"daily": daily, "monthly": monthly, "days": days}
    times = 0
    day3 = []
    for year in range(2019, 2021):
        for month in range(1, 13):
            mon = tostr(year) + "-" + tostr(month)
            monLst = []
            for day in range(1, 32):
                date = tostr(year) + "-" + tostr(month) + "-" + tostr(day)
                lst = []
                for new in news:
                    if new["create_date"] == date:
                        lst.append(new)
                        monLst.append(new)
                        day3.append(new)
                times += 1
                if times == 3:
                    if len(day3) != 0:
                        days[date] = day3
                    day3 = []
                    times = 0
                if len(lst) != 0:
                    daily[date] = lst
            if len(monLst) != 0:
                monthly[mon] = monLst
    return news_list

def arrangeByChannel(news):
    channel = dict()
    for new in news:
        if new['channel'] not in channel.keys():
            channel[new['channel']] = []
            #不存在则新建，存在则加入
            channel[new['channel']].append(new)
        else:
            channel[new['channel']].append(new)
    return channel
```



#### 数目统计-以新闻数量为例

```python
def drawDailyNewsNum(news, mode):
    line = Line()
    line.add_xaxis(list(news.get(mode).keys()))
    y = []
    for i in news.get(mode).keys():
        y.append(len(news.get(mode).get(i)))
    #用字典value的长度来确定新闻数
    line.add_yaxis("新闻数量", y_axis=y)
    line.set_global_opts(title_opts=options.TitleOpts(title=titleTransform("新浪新闻" + str(mode) + "数量"), pos_top='55'))
    return line
```

#### 情感平均-以新闻评论为例

```python
def sina_comment(data, mode, time):
    #data是数据,mode是确定加不加权,time指定按天\月\12天绘图
    line = Line()
    temp = list(arrangeByTime(data).get(time).keys())
    line.add_xaxis(temp)
    data = arrangeByChannel(data)  # 按频道分
    news = dict()
    for i in data.keys():
        news[i] = arrangeByTime(data.get(i)).get(time)
    #频道分完后再按时间分
    value = dict()
    comment_channel = dict()
    for i in news.keys():
        comment_channel[i] = dict()
        value[i] = dict()
        for j in news[i].keys():
            comment_channel[i][j] = divideComment(news[i].get(j))
            #按维度和时间梳理评论
        value[i] = getMood(comment_channel[i], mode)
        #获取评论对应的平均心态值
    for i in value.keys():
        y = []
        for j in temp:
            if j in value.get(i).keys():
                y.append(value.get(i).get(j))
            else:
                y.append(None)
                #可能存在当天没有频道新闻
        if i not in ['js', 'jilin', 'video', 'live']:
            #数据过少,舍弃
            line.add_yaxis(tran(i), y, is_connect_nones=True, is_symbol_show=(time == 'monthly'))
    line.set_global_opts(title_opts=options.TitleOpts(title=titleTransform("新浪新闻评论"+str(mode) + str(time) + "评论情感分析"), pos_top='55'))
    return line


def getMood(comments, mode):
    #简简单单取平均,mode是确定加不加权
    mood = dict()
    for i in comments.keys():
        sum = 0
        times = 0
        if len(comments.get(i)) == 0:
            continue
        for j in comments.get(i):
            if mode == 0:
                temp = str(j['sentiment'])
                if not temp.__contains__("."):
                    #规避可能的不是指定格式的错误
                    continue
                times += 1
                sum += float(temp)
            else:
                temp = str(j['sentiment'])
                if not temp.__contains__("."):
                    #规避可能的不是指定格式的错误
                    continue
                agree = str(j['agree'])
                if not agree.isdigit():
                    continue
                times += max(int(agree), 1)
                sum += float(temp) * max(int(agree), 1)
        mood[i] = str.format("{:.3f}", sum / times)
    return mood
```

#### 示例

[示例页面](https://www.rubisco.cn/picturebed/chart.html)



